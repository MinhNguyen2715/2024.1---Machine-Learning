# -*- coding: utf-8 -*-
"""SVM

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qiI3_Tepvl_HUGtDCa5DbyVMziFhvOl8

# Import library
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt


from sklearn.preprocessing import StandardScaler
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split, cross_validate
from sklearn.svm import SVC
from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import StratifiedKFold, GridSearchCV, cross_val_score


"""# Import data

"""

rice = pd.read_excel("data/rice.xlsx")

le = LabelEncoder()
rice['Class'] = le.fit_transform(rice['Class'])  # Cammeo -> 0 (or 1)
print(le.classes_)

X = rice.drop("Class", axis=1)
y = rice["Class"]
rice.head(5)

"""# Choosing best parameters for SVM"""

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.2, random_state=13, stratify=y)

skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=23)

# Try with logarithmic scale first (0.01, 0.1, 1, 10, 100)
# Then localize around 10: (8,9,10,11,12)
param_grid = {
    'C': [11.5,11.7,11.9,12.1,12.2,12.3,12.5],
    'kernel': ['linear', 'rbf','sigmoid','poly'],
    'gamma': ['scale', 'auto']
}

grid = GridSearchCV(SVC(), param_grid, scoring='accuracy', cv=skf)
grid.fit(X_train, y_train)

print("Best parameters:", grid.best_params_)
print("Best CV accuracy:", grid.best_score_)
best_params = grid.best_params_

final_model = SVC(
    C=grid.best_params_["C"],
    kernel=grid.best_params_["kernel"],
    gamma=grid.best_params_["gamma"]
)

"""# Training SVM"""

final_model.fit(X_train, y_train)

"""# Testing and Showing result"""

y_pred = final_model.predict(X_test)

cm = confusion_matrix(y_test, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=le.classes_)
disp.plot(cmap=plt.cm.Blues)
plt.title("Confusion Matrix")
plt.show()

tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()
# Compute all metrics
accuracy  = (tp + tn) / (tp + tn + fp + fn) * 100
sensitivity = tp / (tp + fn)* 100
specificity = tn / (tn + fp)* 100
precision = tp / (tp + fp)* 100
f1_score = (2 * (precision * sensitivity) / (precision + sensitivity) )
npv = tn / (tn + fn)* 100
fpr = fp / (fp + tn)* 100
fdr = fp / (tp + fp)* 100
fnr = fn / (fn + tp)* 100

# Display
print(f"Accuracy: {accuracy:.2f}")
print(f"Sensitivity (Recall): {sensitivity:.2f}")
print(f"Specificity: {specificity:.2f}")
print(f"Precision: {precision:.2f}")
print(f"F1-Score: {f1_score:.2f}")
print(f"NPV: {npv:.2f}")
print(f"FPR: {fpr:.2f}")
print(f"FDR: {fdr:.2f}")
print(f"FNR: {fnr:.2f}")

# # Cross validation
# scores = cross_val_score(final_model, X_test, y_test, cv=skf)
# print("Cross-validation scores:", scores)
# print("Mean cross-validation score:", scores.mean())